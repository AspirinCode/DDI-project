Train:
[('false', 23664), ('effect', 1669), ('mechanism', 1319), ('advise', 822), ('int', 189)]
129 semi-column

Test:
[('false', 4712), ('effect', 360), ('mechanism', 299), ('advise', 221), ('int', 96)]
28 semi-column

##########################################################################################

* max_sent_len을 50에서 70으로 했을 때 성능 향상 (약 87%)
* BiLSTM의 경우 약 83~84%정도 나옴(CNN보다 좋다고 보긴 어려움)
* rnn에서 self-attention을 쓰면 오히려 성능이 1프로 떨어짐

* batch size의 크기가 performance에 어떻게 영향을 주는지 확인하자
* nb_epoch = 15 정도가 좋을 듯(overfit 문제)